{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e31687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "from transformers import pipeline\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "238b5fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 197\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Type: Front Matter\n",
      "Preview: Kenya Demographic and  Health Survey 2022 Demographic and Health Survey  â€¢  Volume 1  Kenya 2022 Volume 1          Kenya   Demographic and Health Surv ...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Chapter 13: KNOWLEDGE, ATTITUDES, AND BEHAVIOUR RELATED TO HIV, AIDS, AND (intro)\n",
      "Preview: 13 KNOWLEDGE, ATTITUDES, AND BEHAVIOUR RELATED TO HIV, AIDS, AND  TUBERCULOSIS  ................................ ................................ .... ...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Chapter 13 â€“ Section 13.1: Tuberculosis: Knowledge, Diagnosis, and Preventive Treatment\n",
      "Preview: 13.1 Tuberculosis: Knowledge, Diagnosis, and Preventive Treatment  ................................ ... 422  13.1.1  Knowledge and Beliefs about Tuber ...\n",
      "\n",
      "--- Chunk 4 ---\n",
      "Chapter 13 â€“ Section 13.2: Knowledge and Attitudes about Medicines to Treat or Prevent HIV\n",
      "Preview: 13.2 Knowledge and Attitudes about Medicines to Treat or Prevent HIV  ..............................  422 ...\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Chapter 13 â€“ Section 13.3: Discriminatory Attitudes towards People Living with HIV\n",
      "Preview: 13.3 Discriminatory Attitudes towards People Living with HIV  ................................ ............  424 ...\n",
      "\n",
      "--- Chunk 6 ---\n",
      "Chapter 13 â€“ Section 13.4: Multiple Sexual Partners\n",
      "Preview: 13.4 Multiple Sexual Partners  ................................ ................................ ................................ . 425 ...\n",
      "\n",
      "--- Chunk 7 ---\n",
      "Chapter 13 â€“ Section 13.5: Coverage of HIV Testing Services\n",
      "Preview: 13.5 Coverage of HIV Testing Services  ................................ ................................ ..................  426  13.5.1  HIV Testing  ...\n",
      "\n",
      "--- Chunk 8 ---\n",
      "Chapter 13 â€“ Section 13.6: Discl osure, Shame, and Stigma among Self -reported HIV Positive\n",
      "Preview: 13.6 Discl osure, Shame, and Stigma among Self -reported HIV Positive  ...............................  431 ...\n",
      "\n",
      "--- Chunk 9 ---\n",
      "Chapter 13 â€“ Section 13.7: Male Circumcision\n",
      "Preview: 13.7 Male Circumcision  ................................ ................................ ................................ ..........  432 ...\n",
      "\n",
      "--- Chunk 10 ---\n",
      "Chapter 13 â€“ Section 13.8: Self-reporting of Sexually Transmitted Infections\n",
      "Preview: 13.8 Self-reporting of Sexually Transmitted Infections  ................................ ..........................  433 ...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "def clean_title(raw: str) -> str:\n",
    "    \"\"\"Remove trailing spaces, dots, and page numbers.\"\"\"\n",
    "    cleaned = re.sub(r'\\s*[\\.\\s]+[\\d\\s]*$', '', raw)\n",
    "    return cleaned.strip()\n",
    "\n",
    "def extract_chapters(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Find all chapter headings (lines like \"1 INTRODUCTION ...\").\n",
    "    Returns list of dicts with chapter number, title, and start/end positions.\n",
    "    \"\"\"\n",
    "    chapter_pattern = re.compile(\n",
    "        r'^(?!.*Table|.*Figure|.*Map)(\\d{1,2})\\s+([A-Z][A-Z\\s,.-]+?)\\s*$',\n",
    "        re.MULTILINE\n",
    "    )\n",
    "    chapters = []\n",
    "    for match in chapter_pattern.finditer(text):\n",
    "        chapters.append({\n",
    "            'num': match.group(1),\n",
    "            'title': clean_title(match.group(2)),\n",
    "            'start': match.start(),\n",
    "            'end': match.end()\n",
    "        })\n",
    "    return chapters\n",
    "\n",
    "def chunk_kdhs_report(file_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Twoâ€‘level chunking: chapters, then sections within each chapter.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = re.sub(r'\\r\\n', '\\n', text)\n",
    "\n",
    "    # ---- Step 1: Extract chapters ----\n",
    "    chapters = extract_chapters(text)\n",
    "    if not chapters:\n",
    "        raise ValueError(\"No chapters found.\")\n",
    "\n",
    "    # Add a sentinel end for the last chapter\n",
    "    for i in range(len(chapters)):\n",
    "        chap = chapters[i]\n",
    "        chap['end'] = chapters[i+1]['start'] if i+1 < len(chapters) else len(text)\n",
    "\n",
    "    # ---- Step 2: Front matter (before first chapter) ----\n",
    "    chunks = []\n",
    "    if chapters[0]['start'] > 0:\n",
    "        front = text[:chapters[0]['start']].strip()\n",
    "        if front:\n",
    "            chunks.append({\n",
    "                'type': 'front_matter',\n",
    "                'text': front\n",
    "            })\n",
    "\n",
    "    # ---- Step 3: Process each chapter ----\n",
    "    for chap in chapters:\n",
    "        chapter_text = text[chap['start']:chap['end']].strip()\n",
    "        chapter_num = chap['num']\n",
    "        chapter_title = chap['title']\n",
    "\n",
    "        # Find section headings within this chapter's text\n",
    "        # Pattern: line starts with digit.digit, space, then any chars, end of line\n",
    "        section_pattern = re.compile(r'^(\\d+\\.\\d+)\\s+(.+?)\\s*$', re.MULTILINE)\n",
    "        sections = list(section_pattern.finditer(chapter_text))\n",
    "\n",
    "        if not sections:\n",
    "            # Chapter without sections â€“ keep as one chunk\n",
    "            chunks.append({\n",
    "                'type': 'chapter',\n",
    "                'chapter_num': chapter_num,\n",
    "                'chapter_title': chapter_title,\n",
    "                'text': chapter_text\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Chapter intro (before first section)\n",
    "        intro_text = chapter_text[:sections[0].start()].strip()\n",
    "        if intro_text:\n",
    "            chunks.append({\n",
    "                'type': 'chapter_intro',\n",
    "                'chapter_num': chapter_num,\n",
    "                'chapter_title': chapter_title,\n",
    "                'text': intro_text\n",
    "            })\n",
    "\n",
    "        # Each section\n",
    "        for i, sec in enumerate(sections):\n",
    "            sec_num = sec.group(1)\n",
    "            raw_title = sec.group(2)\n",
    "            sec_title = clean_title(raw_title)\n",
    "            sec_start = sec.start()\n",
    "            sec_end = sections[i+1].start() if i+1 < len(sections) else len(chapter_text)\n",
    "            sec_text = chapter_text[sec_start:sec_end].strip()\n",
    "\n",
    "            chunks.append({\n",
    "                'type': 'section',\n",
    "                'chapter_num': chapter_num,\n",
    "                'chapter_title': chapter_title,\n",
    "                'section_num': sec_num,\n",
    "                'section_title': sec_title,\n",
    "                'text': sec_text\n",
    "            })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# ---- Example usage ----\n",
    "if __name__ == \"__main__\":\n",
    "    chunks = chunk_kdhs_report(\"kdhs_2022_extracted.txt\")\n",
    "    print(f\"Total chunks: {len(chunks)}\")\n",
    "\n",
    "    # Show first 10 chunks\n",
    "    for i, c in enumerate(chunks[:10]):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\")\n",
    "        if c['type'] == 'front_matter':\n",
    "            print(\"Type: Front Matter\")\n",
    "        elif c['type'] == 'chapter':\n",
    "            print(f\"Chapter {c['chapter_num']}: {c['chapter_title']} (whole chapter)\")\n",
    "        elif c['type'] == 'chapter_intro':\n",
    "            print(f\"Chapter {c['chapter_num']}: {c['chapter_title']} (intro)\")\n",
    "        else:  # section\n",
    "            print(f\"Chapter {c['chapter_num']} â€“ Section {c['section_num']}: {c['section_title']}\")\n",
    "        print(\"Preview:\", c['text'][:150].replace('\\n', ' '), \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36791d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 1267\n",
      "\n",
      "--- Chunk 1 ---\n",
      "Type: front_matter\n",
      "Preview: Kenya Demographic and  Health Survey 2022 Demographic and Health Survey  â€¢  Volume 1  Kenya 2022 Volume 1          Kenya   Demographic and Health Surv ...\n",
      "\n",
      "--- Chunk 2 ---\n",
      "Type: chapter_intro\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Preview: 1 INTRODUCTION AND SURVEY METHODOLOGY  ................................ ..............................  1 ...\n",
      "\n",
      "--- Chunk 3 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.1: Survey Objectives\n",
      "Preview: 1.1 Survey Objectives  ................................ ................................ ................................ ................  1 ...\n",
      "\n",
      "--- Chunk 4 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.2: Sample Design\n",
      "Preview: 1.2 Sample Design  ................................ ................................ ................................ .....................  1 ...\n",
      "\n",
      "--- Chunk 5 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.3: Questionnaires\n",
      "Preview: 1.3 Questionnaires  ................................ ................................ ................................ .....................  4 ...\n",
      "\n",
      "--- Chunk 6 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.4: Anthropometry Measurements\n",
      "Preview: 1.4 Anthropometry Measurements  ................................ ................................ ............................  5 ...\n",
      "\n",
      "--- Chunk 7 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.5: Training of Trainers and Pretest\n",
      "Preview: 1.5 Training of Trainers and Pretest  ................................ ................................ ..........................  6 ...\n",
      "\n",
      "--- Chunk 8 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.6: Pretest\n",
      "Preview: 1.6 Pretest  ................................ ................................ ................................ ................................ .. 6 ...\n",
      "\n",
      "--- Chunk 9 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.7: Training of Field Staff\n",
      "Preview: 1.7 Training of Field Staff  ................................ ................................ ................................ .........  6 ...\n",
      "\n",
      "--- Chunk 10 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.8: Fieldwork\n",
      "Preview: 1.8 Fieldwork  ................................ ................................ ................................ .............................  7 ...\n",
      "\n",
      "--- Chunk 11 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.9: Data Processing\n",
      "Preview: 1.9 Data Processing  ................................ ................................ ................................ ...................  7 ...\n",
      "\n",
      "--- Chunk 12 ---\n",
      "Type: section\n",
      "Chapter 1: INTRODUCTION AND SURVEY METHODOLOGY\n",
      "Section 1.10: Response Rates\n",
      "Preview: 1.10 Response Rates  ................................ ................................ ................................ ....................  7 ...\n",
      "\n",
      "--- Chunk 13 ---\n",
      "Type: chapter_intro\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Preview: 2 HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION  ................................  9 ...\n",
      "\n",
      "--- Chunk 14 ---\n",
      "Type: section\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Section 2.1: Housing Characteristics\n",
      "Preview: 2.1 Housing Characteristics  ................................ ................................ ................................ ....... 9  2.1.1  Use  ...\n",
      "\n",
      "--- Chunk 15 ---\n",
      "Type: section\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Section 2.2: Household Wealth\n",
      "Preview: 2.2 Household Wealth  ................................ ................................ ................................ .............  12  2.2.1  Hou ...\n",
      "\n",
      "--- Chunk 16 ---\n",
      "Type: section\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Section 2.3: Household Population and Composition\n",
      "Preview: 2.3 Household Population and Composition  ................................ ................................ ...........  13 ...\n",
      "\n",
      "--- Chunk 17 ---\n",
      "Type: section\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Section 2.4: Childrenâ€™s Living Arrangements and Parental Survival\n",
      "Preview: 2.4 Childrenâ€™s Living Arrangements and Parental Survival  ................................ ....................  13 ...\n",
      "\n",
      "--- Chunk 18 ---\n",
      "Type: section\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Section 2.5: Birth Registration\n",
      "Preview: 2.5 Birth Registration  ................................ ................................ ................................ ..............  14 ...\n",
      "\n",
      "--- Chunk 19 ---\n",
      "Type: section\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Section 2.6: Education\n",
      "Preview: 2.6 Education  ................................ ................................ ................................ ...........................  15  2.6 ...\n",
      "\n",
      "--- Chunk 20 ---\n",
      "Type: section\n",
      "Chapter 2: HOUSING CHARACTERISTICS AND HOUSEHOLD POPULATION\n",
      "Section 2.7: Disability\n",
      "Preview: 2.7 Disability  ................................ ................................ ................................ ...........................  18  2. ...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "def clean_title(raw: str) -> str:\n",
    "    \"\"\"Remove trailing spaces, dots, and page numbers.\"\"\"\n",
    "    cleaned = re.sub(r'\\s*[\\.\\s]+[\\d\\s]*$', '', raw)\n",
    "    return cleaned.strip()\n",
    "\n",
    "def extract_chapters(text: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Find all chapter headings.\n",
    "    Pattern: optional leading spaces, then 1-2 digits, space, then any characters to end of line.\n",
    "    \"\"\"\n",
    "    chapter_pattern = re.compile(\n",
    "        r'^\\s*(\\d{1,2})\\s+(.+?)\\s*$',\n",
    "        re.MULTILINE\n",
    "    )\n",
    "    chapters = []\n",
    "    for match in chapter_pattern.finditer(text):\n",
    "        # Basic heuristic: title should be mostly uppercase and reasonably long\n",
    "        raw_title = match.group(2).strip()\n",
    "        title = clean_title(raw_title)\n",
    "        # Skip if title is too short (likely not a real chapter)\n",
    "        if len(title) < 10:\n",
    "            continue\n",
    "        # Skip if title contains common TOC phrases (optional)\n",
    "        if any(word in title.lower() for word in ['table', 'figure', 'list of']):\n",
    "            continue\n",
    "        chapters.append({\n",
    "            'num': match.group(1),\n",
    "            'title': title,\n",
    "            'start': match.start(),\n",
    "            'end': match.end()\n",
    "        })\n",
    "    return chapters\n",
    "\n",
    "def chunk_kdhs_report(file_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Twoâ€‘level chunking: chapters, then sections within each chapter.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    text = re.sub(r'\\r\\n', '\\n', text)\n",
    "\n",
    "    # ---- Step 1: Extract chapters ----\n",
    "    chapters = extract_chapters(text)\n",
    "    if not chapters:\n",
    "        raise ValueError(\"No chapters found.\")\n",
    "\n",
    "    # Add a sentinel end for the last chapter\n",
    "    for i in range(len(chapters)):\n",
    "        chap = chapters[i]\n",
    "        chap['end'] = chapters[i+1]['start'] if i+1 < len(chapters) else len(text)\n",
    "\n",
    "    # ---- Step 2: Front matter (before first chapter) ----\n",
    "    chunks = []\n",
    "    if chapters[0]['start'] > 0:\n",
    "        front = text[:chapters[0]['start']].strip()\n",
    "        if front:\n",
    "            chunks.append({\n",
    "                'type': 'front_matter',\n",
    "                'text': front\n",
    "            })\n",
    "\n",
    "    # ---- Step 3: Process each chapter ----\n",
    "    for chap in chapters:\n",
    "        chapter_text = text[chap['start']:chap['end']].strip()\n",
    "        chapter_num = chap['num']\n",
    "        chapter_title = chap['title']\n",
    "\n",
    "        # Find section headings within this chapter's text\n",
    "        section_pattern = re.compile(r'^\\s*(\\d+\\.\\d+)\\s+(.+?)\\s*$', re.MULTILINE)\n",
    "        sections = list(section_pattern.finditer(chapter_text))\n",
    "\n",
    "        if not sections:\n",
    "            chunks.append({\n",
    "                'type': 'chapter',\n",
    "                'chapter_num': chapter_num,\n",
    "                'chapter_title': chapter_title,\n",
    "                'text': chapter_text\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # Chapter intro (before first section)\n",
    "        intro_text = chapter_text[:sections[0].start()].strip()\n",
    "        if intro_text:\n",
    "            chunks.append({\n",
    "                'type': 'chapter_intro',\n",
    "                'chapter_num': chapter_num,\n",
    "                'chapter_title': chapter_title,\n",
    "                'text': intro_text\n",
    "            })\n",
    "\n",
    "        # Each section\n",
    "        for i, sec in enumerate(sections):\n",
    "            sec_num = sec.group(1)\n",
    "            raw_title = sec.group(2)\n",
    "            sec_title = clean_title(raw_title)\n",
    "            sec_start = sec.start()\n",
    "            sec_end = sections[i+1].start() if i+1 < len(sections) else len(chapter_text)\n",
    "            sec_text = chapter_text[sec_start:sec_end].strip()\n",
    "\n",
    "            chunks.append({\n",
    "                'type': 'section',\n",
    "                'chapter_num': chapter_num,\n",
    "                'chapter_title': chapter_title,\n",
    "                'section_num': sec_num,\n",
    "                'section_title': sec_title,\n",
    "                'text': sec_text\n",
    "            })\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chunks = chunk_kdhs_report(\"kdhs_2022_extracted.txt\")\n",
    "    print(f\"Total chunks: {len(chunks)}\")\n",
    "\n",
    "    # Show first 20 chunks\n",
    "    for i, c in enumerate(chunks[:20]):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\")\n",
    "        print(f\"Type: {c['type']}\")\n",
    "        if c['type'] != 'front_matter':\n",
    "            print(f\"Chapter {c['chapter_num']}: {c['chapter_title']}\")\n",
    "            if c['type'] == 'section':\n",
    "                print(f\"Section {c['section_num']}: {c['section_title']}\")\n",
    "        print(\"Preview:\", c['text'][:150].replace('\\n', ' '), \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8710c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1267 chunks to kdhs_chunks.jsonl\n",
      "\n",
      "ðŸ“„ Sample chunk:\n",
      "{\n",
      "  \"id\": \"chunk_0000\",\n",
      "  \"text\": \"Kenya\\nDemographic and \\nHealth Survey 2022\\nDemographic and Health Survey  \\u2022  Volume 1\\n Kenya 2022\\nVolume 1 \\n   \\n \\n \\nKenya  \\nDemographic and Health Survey  \\n2022  \\n \\nVolume 1  \\n \\n \\n \\n \\nKenya National Bureau of Statistics  \\nNairobi, Kenya  \\n \\nMinistry of Health  \\nNairobi, Kenya  \\n \\nThe DHS Program  \\nICF \\nRockville, Maryland, USA  \\n \\n \\nJune  2023 \\n \\n \\n \\n \\n \\n \\n \\n \\n    \\n    \\n    \\n    \\n   \\n  \\n \\n The 2022 Kenya Demographic and Health Survey (2022 KDHS) was implemented by the Kenya National Bureau \\nof Statistics (KNBS) in collaboration  with the Ministry of Health (MoH)  and other stakeholders . Funding for the \\nsurvey was provided by the Government of K enya, the United States Agency for International Development \\n(USAID), the Bill & Melinda Gates Foundation, the World Bank, the United Nations Children \\u2019s Fund (UNICEF), \\nthe United Nations Population Fund (UNFPA), Nutrition International,  the World Food Programme (WFP), the \\nUnited Nations Entity for Gender Equality and the Em powerment of Women (UN Women), the World Health \\nOrganization  (WHO), the Clinton Health Access Initiative, and the Joint United Nations  Programme on \\nHIV/AIDS (UNAIDS) . The UN Resident Coordinator office assured the coordination of UN agencies supporting \\nthe 2022 KDHS. ICF provided technical assistance through The DHS Program, a USAID -funded project \\nproviding support and technical assistance in implement ing population and health surveys in countries worldwide.  \\nAdditional information about the 2022 KDHS may be obtained from Kenya National Bureau of Statistics (KNBS), \\nP.O. Box 30266 -00100 , GPO Nairobi, Kenya; telephone: +254 -20-331758 3, +254 -20-2911000/1 , +254 -20-\\n3317612/22/23/ 51; email: di rectorgeneral@knbs.or.ke, info@knbs.or.ke; website: www.knbs.or.ke.  \\nInformation about The DHS Program may be obtained from ICF, 530 Gaither Road, Suite 500, Rockville, MD \\n20850, USA; telephone: +1 -301-407-6500; fax: +1 -301-407-6501; email: info@DHSprogram. com; internet: \\nwww.DHSprogram.com.  \\nThe contents of this report are the sole responsibility of KNBS and ICF and do not necessarily reflect the views \\nof USAID, the United States Government, or other donor agencies.  \\nISBN: 978-9914 -49-610-9 \\nRecommended citation:  \\nKNBS and ICF. 202 3. Kenya Demographic and Health Survey 2022 : Volume 1 . Nairobi, Kenya , and Rockville, \\nMaryland, USA: KNBS and ICF.  Contents   \\uf09f  iii CONTENTS   \\n \\nLIST OF TABLES, FIGURES, AND MAPS  ................................ ................................ ............................  ix \\nFOREWORD  ................................ ................................ ................................ ................................ ............  xxv \\nACRONYMS AND ABBREVIATIONS  ................................ ................................ ...............................  xxvii  \\nREADING AND UNDERSTANDING TABLES FROM THE 2022 KENYA DEMOGRAPHIC  \\nAND HEALTH SURVEY (KDHS)  ................................ ................................ ................................ ........  xxix \\nSUSTAINABLE DEVELOPMENT GOALS  ................................ ................................ .....................  xxxvii  \\nMAP OF KENYA  ................................ ................................ ................................ ................................ ........  xl\",\n",
      "  \"type\": \"front_matter\",\n",
      "  \"source\": \"kdhs_2022\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "def chunks_to_jsonl(chunks: List[Dict], output_file: str = \"kdhs_chunks.jsonl\"):\n",
    "    \"\"\"\n",
    "    Convert chunk dictionaries to JSONL format for RAG indexing.\n",
    "    Each line becomes a JSON object with consistent fields.\n",
    "    \"\"\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Creating a clean document object\n",
    "            doc = {\n",
    "                'id': f'chunk_{i:04d}',\n",
    "                'text': chunk['text'],\n",
    "                'type': chunk['type']\n",
    "            }\n",
    "            \n",
    "            # Adding chapter info if present\n",
    "            if 'chapter_num' in chunk:\n",
    "                doc['chapter_num'] = chunk['chapter_num']\n",
    "                doc['chapter_title'] = chunk['chapter_title']\n",
    "            \n",
    "            # Adding section info if present\n",
    "            if 'section_num' in chunk:\n",
    "                doc['section_num'] = chunk['section_num']\n",
    "                doc['section_title'] = chunk['section_title']\n",
    "            \n",
    "            # Adding a source field for filtering (like 'course' in the notebook)\n",
    "            doc['source'] = 'kdhs_2022'\n",
    "            \n",
    "            # Writing as JSON line\n",
    "            f_out.write(json.dumps(doc) + '\\n')\n",
    "    \n",
    "    print(f\"Saved {len(chunks)} chunks to {output_file}\")\n",
    "    \n",
    "    # Showing a sample\n",
    "    with open(output_file, 'r') as f:\n",
    "        first_line = f.readline().strip()\n",
    "        print(\"\\nðŸ“„ Sample chunk:\")\n",
    "        print(json.dumps(json.loads(first_line), indent=2))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # If you have chunks in memory from previous session:\n",
    "    chunks_to_jsonl(chunks)\n",
    "    \n",
    "    # If you need to load from a file:\n",
    "    # with open('chunks.json', 'r') as f:\n",
    "    #     chunks = json.load(f)\n",
    "    # chunks_to_jsonl(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76cef64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot connect to Elasticsearch\n",
      "Make sure Elasticsearch is running on http://localhost:9200\n"
     ]
    }
   ],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200')\n",
    "\n",
    "# Test connection\n",
    "if es_client.ping():\n",
    "    print(\"Connected to Elasticsearch\")\n",
    "else:\n",
    "    print(\"Cannot connect to Elasticsearch\")\n",
    "    print(\"Make sure Elasticsearch is running on http://localhost:9200\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_Zoomcamp (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
